{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 圖片前處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['..\\\\data\\\\KZZG.jpg',\n",
       " '..\\\\data\\\\VVHE.jpg',\n",
       " '..\\\\data\\\\CRNJ.jpg',\n",
       " '..\\\\data\\\\LRKP.jpg',\n",
       " '..\\\\data\\\\TVVT.jpg']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_filenames(dataset_dir):\n",
    "    captcha_names = []\n",
    "    for filename in sorted(os.listdir(dataset_dir)):\n",
    "        path = os.path.join(dataset_dir, filename)\n",
    "        captcha_names.append(path)\n",
    "    return captcha_names\n",
    "\n",
    "dataPath = r'..\\data'\n",
    "\n",
    "image_filenames = get_filenames(dataPath)    # 取得所有圖片的檔案路徑\n",
    "random.shuffle(image_filenames)              # 打亂順序\n",
    "\n",
    "n_train = 5600    # 訓練集數量\n",
    "train_filenames = image_filenames[:n_train]    # 訓練集片的檔案路徑\n",
    "test_filenames = image_filenames[n_train:]     # 測試集片的檔案路徑\n",
    "\n",
    "# SHOW\n",
    "train_filenames[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Converting image and label 5600/5600\n",
      ">> Converting image and label 1400/1400\n",
      "X_train: (5600, 40, 120)\n",
      "y_train: (5600, 4)\n",
      "X_test: (1400, 40, 120)\n",
      "y_test: (1400, 4)\n",
      "[10 25 25  6]\n"
     ]
    }
   ],
   "source": [
    "def convert_dataset(filenames):\n",
    "    \n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for i, filename in enumerate(filenames):\n",
    "        oneHots = []\n",
    "        sys.stdout.write('\\r>> Converting image and label %d/%d' % (i + 1, len(filenames)))\n",
    "        sys.stdout.flush()\n",
    "        time.sleep(0.0001)\n",
    "        \n",
    "        # 處理圖片\n",
    "        img = cv2.imread(filename)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        img = np.asarray(img)\n",
    "        img[img>=img[0, :]-5]=255\n",
    "        img[img>=img[-1, :]-5]=255\n",
    "        \n",
    "        img = img * 1.7\n",
    "        img[img>255] = 255.0\n",
    "        img[img<255] = 0\n",
    "        \n",
    "        img = img.astype('uint8')\n",
    "        img = cv2.fastNlMeansDenoising(img, None, 65, 7, 21)\n",
    "        img[img>230]=255\n",
    "        img[img<255]=0\n",
    "        \n",
    "        img = img.astype(float)\n",
    "        img = img / 255.0              # 0 to 1\n",
    "        img = np.subtract(img, 0.5)    # -0.5 to 0.5\n",
    "        img = np.multiply(img, 2.0)    # -1 to 1\n",
    "        \n",
    "\n",
    "        \n",
    "        # 處理標籤\n",
    "        label = filename.split('\\\\')[-1][:4]    # 取得驗證碼(檔名)\n",
    "        \n",
    "        for i in range(len(label)):\n",
    "            oneHots.append(ord(label[i])-65)\n",
    "        \n",
    "        # append feature\n",
    "        images.append(img)\n",
    "        labels.append(oneHots)\n",
    "    \n",
    "    sys.stdout.write('\\n')\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "X_train, y_train = convert_dataset(train_filenames)\n",
    "X_test, y_test = convert_dataset(test_filenames)\n",
    "\n",
    "# SHOW\n",
    "print('X_train:', X_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('X_test:', X_test.shape)\n",
    "print('y_test:', y_test.shape)\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 檢測數據"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "idx = random.randint(0, 4000)\n",
    "y = ''\n",
    "for index in range(len(y_train[idx])):\n",
    "    y += chr(y_train[idx][index]+65)\n",
    "plt.imshow(X_train[idx], cmap='gray')\n",
    "plt.title(y, fontsize=18)\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建構網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 10    #80\n",
    "BATCH_SIZE = 20\n",
    "DROPOUT = 0.7\n",
    "LAMBDA = 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(input_, W, b, name):\n",
    "    with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n",
    "        x = tf.nn.conv2d(input_, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "def flatten(layer):\n",
    "    num_features = layer.shape[1:].num_elements()\n",
    "    flat = tf.reshape(layer, [-1, num_features])\n",
    "    return flat\n",
    "\n",
    "def get_weight_bias(weight_size, layer):\n",
    "    weight = tf.Variable(tf.random_normal(weight_size), name='w'+layer)\n",
    "    bias = tf.Variable(tf.random_normal([weight_size[-1]]), name='b'+layer)\n",
    "    return weight, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def captcha_network(inputs, num_classes):\n",
    "    W1, b1 = get_weight_bias([3, 3, 1, 64], '1')\n",
    "    W2, b2 = get_weight_bias([3, 3, 64, 128], '2')\n",
    "\n",
    "    l2_regularization = tf.nn.l2_loss(W1) + tf.nn.l2_loss(W2)\n",
    "        \n",
    "    x = conv2d(inputs, W1, b1, name='conv1')\n",
    "    x = tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME', name='pool1')\n",
    "        \n",
    "    x = conv2d(x, W2, b2, name='conv2')\n",
    "    x = tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME', name='pool2')\n",
    "        \n",
    "    x = tf.nn.dropout(x, drop)\n",
    "        \n",
    "    x = flatten(x)\n",
    "        \n",
    "    x0 = tf.layers.dense(x, units=26, name='x0')\n",
    "    x1 = tf.layers.dense(x, units=26, name='x1')\n",
    "    x2 = tf.layers.dense(x, units=26, name='x2')\n",
    "    x3 = tf.layers.dense(x, units=26, name='x3')\n",
    "    \n",
    "    return l2_regularization, x0, x1, x2, x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 40, 120], name='input')\n",
    "y0 = tf.placeholder(tf.float32, [None])\n",
    "y1 = tf.placeholder(tf.float32, [None])\n",
    "y2 = tf.placeholder(tf.float32, [None])\n",
    "y3 = tf.placeholder(tf.float32, [None])\n",
    "drop = tf.placeholder(tf.float32, name='dropout')\n",
    "lamb = tf.placeholder(tf.float32, name='lambda')\n",
    "\n",
    "X_reshape = tf.expand_dims(X, -1)    # 將尺寸1插入張量的維度\n",
    "regularization, logit0, logit1, logit2, logit3 = captcha_network(X_reshape, 26)\n",
    "\n",
    "oneHotLabel0 = tf.one_hot(indices=tf.cast(y0, tf.int32), depth=26)\n",
    "oneHotLabel1 = tf.one_hot(indices=tf.cast(y1, tf.int32), depth=26)\n",
    "oneHotLabel2 = tf.one_hot(indices=tf.cast(y2, tf.int32), depth=26)\n",
    "oneHotLabel3 = tf.one_hot(indices=tf.cast(y3, tf.int32), depth=26)\n",
    "\n",
    "\n",
    "# loss\n",
    "loss0 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=oneHotLabel0, logits=logit0))\n",
    "loss1 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=oneHotLabel1, logits=logit1))\n",
    "loss2 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=oneHotLabel2, logits=logit2))\n",
    "loss3 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=oneHotLabel3, logits=logit3))\n",
    "\n",
    "totalLoss = (loss0+loss1+loss2+loss3)/4 + lamb*regularization\n",
    "\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE).minimize(totalLoss)\n",
    "\n",
    "\n",
    "# accuracy\n",
    "y_pred0 = tf.nn.softmax(logit0, name='pred0')\n",
    "y_pred1 = tf.nn.softmax(logit1, name='pred1')\n",
    "y_pred2 = tf.nn.softmax(logit2, name='pred2')\n",
    "y_pred3 = tf.nn.softmax(logit3, name='pred3')\n",
    "\n",
    "correct_pre0 = tf.equal(tf.argmax(oneHotLabel0, 1), tf.argmax(y_pred0, 1))\n",
    "correct_pre1 = tf.equal(tf.argmax(oneHotLabel1, 1), tf.argmax(y_pred1, 1))\n",
    "correct_pre2 = tf.equal(tf.argmax(oneHotLabel2, 1), tf.argmax(y_pred2, 1))\n",
    "correct_pre3 = tf.equal(tf.argmax(oneHotLabel3, 1), tf.argmax(y_pred3, 1))\n",
    "    \n",
    "accuracy0 = tf.reduce_mean(tf.cast(correct_pre0, tf.float32))\n",
    "accuracy1 = tf.reduce_mean(tf.cast(correct_pre1, tf.float32))\n",
    "accuracy2 = tf.reduce_mean(tf.cast(correct_pre2, tf.float32))\n",
    "accuracy3 = tf.reduce_mean(tf.cast(correct_pre3, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomize(x, y):\n",
    "    permutation = np.random.permutation(y.shape[0])\n",
    "    shuffled_x = x[permutation, :]\n",
    "    shuffled_y = y[permutation]\n",
    "    return shuffled_x, shuffled_y\n",
    "\n",
    "def get_next_batch(x, y, start, end):\n",
    "    x_batch = x[start:end]\n",
    "    y_batch = y[start:end]\n",
    "    return x_batch, y_batch\n",
    "\n",
    "def split_batch_label(batchLabel):\n",
    "    batchLabel0 = [splitLabel[0] for splitLabel in batchLabel]\n",
    "    batchLabel1 = [splitLabel[1] for splitLabel in batchLabel]\n",
    "    batchLabel2 = [splitLabel[2] for splitLabel in batchLabel]\n",
    "    batchLabel3 = [splitLabel[3] for splitLabel in batchLabel]\n",
    "    return batchLabel0, batchLabel1, batchLabel2, batchLabel3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________________________________________________________________\n",
      "Epoch: 1\n",
      "---------------------------------------------------------------------------\n",
      "Iteration: 20/280\t loss: 2099.200\t Accuracy: 0.10, 0.05, 0.00, 0.20\n",
      "Iteration: 40/280\t loss: 396.311\t Accuracy: 0.15, 0.10, 0.15, 0.05\n",
      "Iteration: 60/280\t loss: 192.991\t Accuracy: 0.00, 0.15, 0.10, 0.35\n",
      "Iteration: 80/280\t loss: 86.981\t Accuracy: 0.15, 0.30, 0.45, 0.30\n",
      "Iteration: 100/280\t loss: 50.458\t Accuracy: 0.40, 0.40, 0.50, 0.35\n",
      "Iteration: 120/280\t loss: 43.071\t Accuracy: 0.45, 0.45, 0.35, 0.35\n",
      "Iteration: 140/280\t loss: 35.346\t Accuracy: 0.60, 0.55, 0.35, 0.40\n",
      "Iteration: 160/280\t loss: 27.650\t Accuracy: 0.45, 0.50, 0.60, 0.60\n",
      "Iteration: 180/280\t loss: 22.437\t Accuracy: 0.60, 0.65, 0.70, 0.70\n",
      "Iteration: 200/280\t loss: 17.385\t Accuracy: 0.55, 0.75, 0.70, 0.75\n",
      "Iteration: 220/280\t loss: 6.553\t Accuracy: 0.75, 0.75, 0.85, 0.75\n",
      "Iteration: 240/280\t loss: 5.481\t Accuracy: 0.85, 0.90, 0.95, 0.80\n",
      "Iteration: 260/280\t loss: 12.486\t Accuracy: 0.75, 0.65, 0.70, 0.65\n",
      "Iteration: 280/280\t loss: 13.102\t Accuracy: 0.85, 0.90, 0.70, 0.75\n",
      "---------------------------------------------------------------------------\n",
      "test_loss: 10.633\t Test Accuracy: 0.84, 0.75, 0.77, 0.79\n",
      "___________________________________________________________________________\n",
      "\n",
      "\n",
      "___________________________________________________________________________\n",
      "Epoch: 2\n",
      "---------------------------------------------------------------------------\n",
      "Iteration: 20/280\t loss: 3.378\t Accuracy: 0.80, 0.90, 0.90, 0.80\n",
      "Iteration: 40/280\t loss: 3.646\t Accuracy: 0.95, 0.95, 0.85, 0.90\n",
      "Iteration: 60/280\t loss: 1.243\t Accuracy: 0.85, 1.00, 1.00, 0.95\n",
      "Iteration: 80/280\t loss: 1.194\t Accuracy: 0.90, 0.90, 1.00, 0.90\n",
      "Iteration: 100/280\t loss: 2.541\t Accuracy: 0.85, 0.90, 0.90, 0.95\n",
      "Iteration: 120/280\t loss: 3.291\t Accuracy: 0.75, 0.95, 0.90, 0.95\n",
      "Iteration: 140/280\t loss: 1.132\t Accuracy: 1.00, 0.85, 1.00, 0.95\n",
      "Iteration: 160/280\t loss: 2.890\t Accuracy: 0.80, 0.95, 0.95, 0.95\n",
      "Iteration: 180/280\t loss: 4.213\t Accuracy: 0.85, 0.95, 0.85, 0.90\n",
      "Iteration: 200/280\t loss: 2.489\t Accuracy: 0.90, 0.90, 0.75, 0.95\n",
      "Iteration: 220/280\t loss: 2.133\t Accuracy: 0.85, 0.90, 1.00, 0.95\n",
      "Iteration: 240/280\t loss: 1.991\t Accuracy: 0.95, 0.95, 0.95, 0.90\n",
      "Iteration: 260/280\t loss: 3.154\t Accuracy: 1.00, 0.90, 0.95, 0.95\n",
      "Iteration: 280/280\t loss: 1.439\t Accuracy: 1.00, 0.90, 0.90, 0.95\n",
      "---------------------------------------------------------------------------\n",
      "test_loss: 4.059\t Test Accuracy: 0.91, 0.87, 0.83, 0.91\n",
      "___________________________________________________________________________\n",
      "\n",
      "\n",
      "___________________________________________________________________________\n",
      "Epoch: 3\n",
      "---------------------------------------------------------------------------\n",
      "Iteration: 20/280\t loss: 0.658\t Accuracy: 0.95, 0.95, 0.90, 1.00\n",
      "Iteration: 40/280\t loss: 0.019\t Accuracy: 1.00, 1.00, 1.00, 0.95\n",
      "Iteration: 60/280\t loss: 0.555\t Accuracy: 1.00, 1.00, 1.00, 0.95\n",
      "Iteration: 80/280\t loss: 1.947\t Accuracy: 0.95, 0.95, 0.95, 0.95\n",
      "Iteration: 100/280\t loss: 0.458\t Accuracy: 1.00, 0.95, 1.00, 1.00\n",
      "Iteration: 120/280\t loss: 1.848\t Accuracy: 0.95, 0.95, 0.90, 0.95\n",
      "Iteration: 140/280\t loss: 1.378\t Accuracy: 0.95, 0.90, 0.95, 0.95\n",
      "Iteration: 160/280\t loss: 0.000\t Accuracy: 1.00, 1.00, 1.00, 1.00\n",
      "Iteration: 180/280\t loss: 0.870\t Accuracy: 0.90, 1.00, 1.00, 0.95\n",
      "Iteration: 200/280\t loss: 1.039\t Accuracy: 1.00, 1.00, 1.00, 0.80\n",
      "Iteration: 220/280\t loss: 2.192\t Accuracy: 0.95, 1.00, 0.95, 0.90\n",
      "Iteration: 240/280\t loss: 0.060\t Accuracy: 1.00, 1.00, 0.90, 1.00\n",
      "Iteration: 260/280\t loss: 0.652\t Accuracy: 0.95, 0.95, 0.95, 0.95\n",
      "Iteration: 280/280\t loss: 0.284\t Accuracy: 0.90, 0.90, 1.00, 0.95\n",
      "---------------------------------------------------------------------------\n",
      "test_loss: 3.870\t Test Accuracy: 0.88, 0.85, 0.89, 0.92\n",
      "___________________________________________________________________________\n",
      "\n",
      "\n",
      "___________________________________________________________________________\n",
      "Epoch: 4\n",
      "---------------------------------------------------------------------------\n",
      "Iteration: 20/280\t loss: 1.628\t Accuracy: 0.95, 0.90, 0.95, 1.00\n",
      "Iteration: 40/280\t loss: 0.015\t Accuracy: 1.00, 1.00, 1.00, 1.00\n",
      "Iteration: 60/280\t loss: 1.355\t Accuracy: 0.90, 0.95, 0.90, 1.00\n",
      "Iteration: 80/280\t loss: 1.393\t Accuracy: 1.00, 0.85, 1.00, 0.90\n",
      "Iteration: 100/280\t loss: 0.929\t Accuracy: 0.90, 0.90, 1.00, 1.00\n",
      "Iteration: 120/280\t loss: 0.000\t Accuracy: 1.00, 1.00, 1.00, 1.00\n",
      "Iteration: 140/280\t loss: 1.251\t Accuracy: 1.00, 0.90, 0.95, 1.00\n",
      "Iteration: 160/280\t loss: 0.464\t Accuracy: 0.95, 1.00, 1.00, 1.00\n",
      "Iteration: 180/280\t loss: 0.571\t Accuracy: 1.00, 0.90, 1.00, 1.00\n",
      "Iteration: 200/280\t loss: 0.039\t Accuracy: 1.00, 1.00, 1.00, 0.95\n",
      "Iteration: 220/280\t loss: 0.837\t Accuracy: 1.00, 0.95, 1.00, 0.95\n",
      "Iteration: 240/280\t loss: 3.328\t Accuracy: 0.85, 0.90, 1.00, 0.90\n",
      "Iteration: 260/280\t loss: 1.930\t Accuracy: 0.95, 1.00, 0.95, 0.85\n",
      "Iteration: 280/280\t loss: 0.471\t Accuracy: 0.90, 1.00, 1.00, 1.00\n",
      "---------------------------------------------------------------------------\n",
      "test_loss: 3.443\t Test Accuracy: 0.87, 0.90, 0.94, 0.89\n",
      "___________________________________________________________________________\n",
      "\n",
      "\n",
      "___________________________________________________________________________\n",
      "Epoch: 5\n",
      "---------------------------------------------------------------------------\n",
      "Iteration: 20/280\t loss: 0.052\t Accuracy: 1.00, 1.00, 1.00, 0.95\n",
      "Iteration: 40/280\t loss: 1.234\t Accuracy: 0.95, 0.90, 0.95, 1.00\n",
      "Iteration: 60/280\t loss: 0.436\t Accuracy: 1.00, 1.00, 0.90, 0.95\n",
      "Iteration: 80/280\t loss: 0.340\t Accuracy: 0.95, 1.00, 1.00, 0.90\n",
      "Iteration: 100/280\t loss: 1.247\t Accuracy: 0.90, 0.85, 0.95, 1.00\n",
      "Iteration: 120/280\t loss: 0.127\t Accuracy: 1.00, 1.00, 1.00, 0.95\n",
      "Iteration: 140/280\t loss: 0.716\t Accuracy: 1.00, 0.95, 0.95, 1.00\n",
      "Iteration: 160/280\t loss: 0.436\t Accuracy: 1.00, 0.80, 1.00, 1.00\n",
      "Iteration: 180/280\t loss: 0.675\t Accuracy: 1.00, 0.95, 0.90, 1.00\n",
      "Iteration: 200/280\t loss: 0.910\t Accuracy: 1.00, 0.90, 0.95, 0.95\n",
      "Iteration: 220/280\t loss: 0.060\t Accuracy: 0.95, 1.00, 1.00, 1.00\n",
      "Iteration: 240/280\t loss: 0.232\t Accuracy: 0.95, 0.95, 0.90, 1.00\n",
      "Iteration: 260/280\t loss: 1.407\t Accuracy: 1.00, 0.90, 1.00, 0.90\n",
      "Iteration: 280/280\t loss: 0.968\t Accuracy: 1.00, 0.95, 0.90, 1.00\n",
      "---------------------------------------------------------------------------\n",
      "test_loss: 2.463\t Test Accuracy: 0.92, 0.94, 0.87, 0.92\n",
      "___________________________________________________________________________\n",
      "\n",
      "\n",
      "___________________________________________________________________________\n",
      "Epoch: 6\n",
      "---------------------------------------------------------------------------\n",
      "Iteration: 20/280\t loss: 0.248\t Accuracy: 0.85, 1.00, 1.00, 1.00\n",
      "Iteration: 40/280\t loss: 0.805\t Accuracy: 0.95, 0.95, 0.95, 0.95\n",
      "Iteration: 60/280\t loss: 0.288\t Accuracy: 1.00, 1.00, 1.00, 0.95\n",
      "Iteration: 80/280\t loss: 1.119\t Accuracy: 0.90, 0.95, 1.00, 1.00\n",
      "Iteration: 100/280\t loss: 0.035\t Accuracy: 1.00, 1.00, 1.00, 0.95\n",
      "Iteration: 120/280\t loss: 0.567\t Accuracy: 0.95, 1.00, 1.00, 0.95\n",
      "Iteration: 140/280\t loss: 0.253\t Accuracy: 1.00, 0.95, 1.00, 1.00\n",
      "Iteration: 160/280\t loss: 0.441\t Accuracy: 0.85, 1.00, 1.00, 1.00\n",
      "Iteration: 180/280\t loss: 0.030\t Accuracy: 0.95, 0.95, 1.00, 1.00\n",
      "Iteration: 200/280\t loss: 0.057\t Accuracy: 0.95, 0.95, 1.00, 1.00\n",
      "Iteration: 220/280\t loss: 0.000\t Accuracy: 1.00, 1.00, 1.00, 1.00\n",
      "Iteration: 240/280\t loss: 0.544\t Accuracy: 1.00, 0.90, 1.00, 0.90\n",
      "Iteration: 260/280\t loss: 0.087\t Accuracy: 0.95, 1.00, 1.00, 1.00\n",
      "Iteration: 280/280\t loss: 0.022\t Accuracy: 1.00, 1.00, 0.95, 1.00\n",
      "---------------------------------------------------------------------------\n",
      "test_loss: 2.275\t Test Accuracy: 0.92, 0.95, 0.92, 0.89\n",
      "___________________________________________________________________________\n",
      "\n",
      "\n",
      "___________________________________________________________________________\n",
      "Epoch: 7\n",
      "---------------------------------------------------------------------------\n",
      "Iteration: 20/280\t loss: 0.421\t Accuracy: 1.00, 1.00, 0.95, 1.00\n",
      "Iteration: 40/280\t loss: 0.754\t Accuracy: 1.00, 0.95, 1.00, 1.00\n",
      "Iteration: 60/280\t loss: 0.000\t Accuracy: 1.00, 1.00, 1.00, 1.00\n",
      "Iteration: 80/280\t loss: 0.088\t Accuracy: 0.95, 1.00, 1.00, 1.00\n",
      "Iteration: 100/280\t loss: 0.286\t Accuracy: 1.00, 1.00, 0.90, 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 120/280\t loss: 0.000\t Accuracy: 1.00, 1.00, 1.00, 1.00\n",
      "Iteration: 140/280\t loss: 0.420\t Accuracy: 0.95, 1.00, 1.00, 0.95\n",
      "Iteration: 160/280\t loss: 0.429\t Accuracy: 1.00, 1.00, 0.95, 1.00\n",
      "Iteration: 180/280\t loss: 0.219\t Accuracy: 1.00, 1.00, 1.00, 0.95\n",
      "Iteration: 200/280\t loss: 0.174\t Accuracy: 1.00, 1.00, 0.95, 0.95\n",
      "Iteration: 220/280\t loss: 0.177\t Accuracy: 0.95, 0.95, 1.00, 1.00\n",
      "Iteration: 240/280\t loss: 0.367\t Accuracy: 0.95, 0.95, 1.00, 0.95\n",
      "Iteration: 260/280\t loss: 0.109\t Accuracy: 1.00, 1.00, 0.90, 0.95\n",
      "Iteration: 280/280\t loss: 0.265\t Accuracy: 1.00, 1.00, 0.95, 1.00\n",
      "---------------------------------------------------------------------------\n",
      "test_loss: 2.315\t Test Accuracy: 0.94, 0.95, 0.91, 0.88\n",
      "___________________________________________________________________________\n",
      "\n",
      "\n",
      "___________________________________________________________________________\n",
      "Epoch: 8\n",
      "---------------------------------------------------------------------------\n",
      "Iteration: 20/280\t loss: 0.000\t Accuracy: 1.00, 1.00, 1.00, 1.00\n",
      "Iteration: 40/280\t loss: 0.081\t Accuracy: 1.00, 1.00, 1.00, 0.95\n",
      "Iteration: 60/280\t loss: 0.000\t Accuracy: 1.00, 1.00, 1.00, 1.00\n",
      "Iteration: 80/280\t loss: 0.000\t Accuracy: 1.00, 1.00, 1.00, 1.00\n",
      "Iteration: 100/280\t loss: 0.184\t Accuracy: 1.00, 1.00, 1.00, 0.90\n",
      "Iteration: 120/280\t loss: 0.415\t Accuracy: 1.00, 1.00, 1.00, 0.95\n",
      "Iteration: 140/280\t loss: 0.761\t Accuracy: 1.00, 0.95, 0.95, 0.95\n",
      "Iteration: 160/280\t loss: 0.000\t Accuracy: 1.00, 1.00, 1.00, 1.00\n",
      "Iteration: 180/280\t loss: 0.167\t Accuracy: 1.00, 1.00, 0.95, 0.95\n",
      "Iteration: 200/280\t loss: 0.482\t Accuracy: 0.95, 0.95, 1.00, 1.00\n",
      "Iteration: 220/280\t loss: 0.789\t Accuracy: 0.95, 1.00, 0.95, 0.95\n",
      "Iteration: 240/280\t loss: 0.087\t Accuracy: 1.00, 1.00, 1.00, 0.95\n",
      "Iteration: 260/280\t loss: 0.000\t Accuracy: 1.00, 1.00, 1.00, 1.00\n",
      "Iteration: 280/280\t loss: 0.205\t Accuracy: 1.00, 1.00, 0.95, 1.00\n",
      "---------------------------------------------------------------------------\n",
      "test_loss: 1.649\t Test Accuracy: 0.93, 0.90, 0.92, 0.93\n",
      "___________________________________________________________________________\n",
      "\n",
      "\n",
      "___________________________________________________________________________\n",
      "Epoch: 9\n",
      "---------------------------------------------------------------------------\n",
      "Iteration: 20/280\t loss: 0.088\t Accuracy: 0.90, 1.00, 1.00, 1.00\n",
      "Iteration: 40/280\t loss: 0.055\t Accuracy: 1.00, 1.00, 0.95, 0.95\n",
      "Iteration: 60/280\t loss: 0.013\t Accuracy: 1.00, 0.95, 1.00, 1.00\n",
      "Iteration: 80/280\t loss: 0.080\t Accuracy: 1.00, 1.00, 1.00, 0.95\n",
      "Iteration: 100/280\t loss: 0.238\t Accuracy: 0.95, 1.00, 0.95, 1.00\n",
      "Iteration: 120/280\t loss: 0.444\t Accuracy: 0.95, 0.90, 1.00, 1.00\n",
      "Iteration: 140/280\t loss: 0.000\t Accuracy: 1.00, 1.00, 1.00, 1.00\n",
      "Iteration: 160/280\t loss: 0.153\t Accuracy: 0.95, 1.00, 1.00, 1.00\n",
      "Iteration: 180/280\t loss: 0.115\t Accuracy: 0.95, 1.00, 0.95, 0.95\n",
      "Iteration: 200/280\t loss: 0.083\t Accuracy: 1.00, 1.00, 1.00, 0.95\n",
      "Iteration: 220/280\t loss: 0.000\t Accuracy: 1.00, 1.00, 1.00, 1.00\n",
      "Iteration: 240/280\t loss: 0.506\t Accuracy: 1.00, 1.00, 1.00, 0.95\n",
      "Iteration: 260/280\t loss: 0.434\t Accuracy: 1.00, 1.00, 0.90, 0.95\n",
      "Iteration: 280/280\t loss: 0.000\t Accuracy: 1.00, 1.00, 1.00, 1.00\n",
      "---------------------------------------------------------------------------\n",
      "test_loss: 0.939\t Test Accuracy: 0.95, 0.94, 0.95, 0.94\n",
      "___________________________________________________________________________\n",
      "\n",
      "\n",
      "___________________________________________________________________________\n",
      "Epoch: 10\n",
      "---------------------------------------------------------------------------\n",
      "Iteration: 20/280\t loss: 0.000\t Accuracy: 1.00, 1.00, 1.00, 1.00\n",
      "Iteration: 40/280\t loss: 0.000\t Accuracy: 1.00, 1.00, 1.00, 1.00\n",
      "Iteration: 60/280\t loss: 0.021\t Accuracy: 0.95, 1.00, 1.00, 1.00\n",
      "Iteration: 80/280\t loss: 0.000\t Accuracy: 1.00, 1.00, 1.00, 1.00\n",
      "Iteration: 100/280\t loss: 0.000\t Accuracy: 1.00, 1.00, 1.00, 1.00\n",
      "Iteration: 120/280\t loss: 0.002\t Accuracy: 1.00, 1.00, 1.00, 1.00\n",
      "Iteration: 140/280\t loss: 0.092\t Accuracy: 1.00, 0.95, 1.00, 1.00\n",
      "Iteration: 160/280\t loss: 0.008\t Accuracy: 1.00, 1.00, 1.00, 1.00\n",
      "Iteration: 180/280\t loss: 0.087\t Accuracy: 1.00, 1.00, 0.95, 1.00\n",
      "Iteration: 200/280\t loss: 0.181\t Accuracy: 1.00, 0.95, 1.00, 1.00\n",
      "Iteration: 220/280\t loss: 0.000\t Accuracy: 1.00, 1.00, 1.00, 1.00\n",
      "Iteration: 240/280\t loss: 0.175\t Accuracy: 1.00, 1.00, 0.95, 1.00\n",
      "Iteration: 260/280\t loss: 0.572\t Accuracy: 1.00, 0.95, 0.90, 1.00\n",
      "Iteration: 280/280\t loss: 0.163\t Accuracy: 1.00, 1.00, 1.00, 0.95\n",
      "---------------------------------------------------------------------------\n",
      "test_loss: 0.904\t Test Accuracy: 0.95, 0.93, 0.95, 0.95\n",
      "___________________________________________________________________________\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'lite'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-649aa6cfd596>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;31m# save_path = saver.save(sess, '../save_model/model.ckpt')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m \u001b[0mtflite_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoco_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0my_pred0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../tfliteModel/model.tflite'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtflite_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'lite'"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "NUM_ITERATION = int(len(y_train) / BATCH_SIZE)         # 跑完一個 epoch 所需要的 iteration 次數\n",
    "NUM_ITERATION_TEST = int(len(y_test) / BATCH_SIZE)     # 跑完一個 test set 所需要的 iteration 次數\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('___________________________________________________________________________')\n",
    "    print('Epoch: {}'.format(epoch + 1))\n",
    "    print('---------------------------------------------------------------------------')\n",
    "    \n",
    "    X_train, y_train = randomize(X_train, y_train)    # 打亂訓練集，避免每次批次都是相同的圖片分布\n",
    "\n",
    "    for iteration in range(NUM_ITERATION):\n",
    "        \n",
    "        # 批次處理\n",
    "        start = iteration * BATCH_SIZE\n",
    "        end = start + BATCH_SIZE\n",
    "        batch_X, batch_y = get_next_batch(X_train, y_train, start, end)\n",
    "        batch_y0, batch_y1, batch_y2, batch_y3 = split_batch_label(batch_y)\n",
    "        \n",
    "        # 執行權重優化\n",
    "        sess.run(train_op, \n",
    "                 feed_dict={X: batch_X, y0: batch_y0, y1: batch_y1, y2: batch_y2, y3: batch_y3, drop: DROPOUT, lamb: LAMBDA})\n",
    "        \n",
    "        # 印出訓練集的 Loss 以及 Accuracy\n",
    "        if (iteration+1) % 20 == 0:\n",
    "            \n",
    "            # 取得該批次的 loss 及 Accuracy\n",
    "            loss, acc0, acc1, acc2, acc3 = sess.run([totalLoss, accuracy0, accuracy1, accuracy2, accuracy3], \n",
    "                                                    feed_dict={X: batch_X, y0: batch_y0, y1: batch_y1, y2: batch_y2, y3: batch_y3, \n",
    "                                                               drop: DROPOUT, lamb: 0})\n",
    "            \n",
    "            print('Iteration: {:2d}/{}\\t loss: {:.3f}\\t Accuracy: {:.2f}, {:.2f}, {:.2f}, {:.2f}'\n",
    "                  .format(iteration+1, NUM_ITERATION, loss, acc0, acc1, acc2, acc3))\n",
    "\n",
    "\n",
    "    batch_loss, batch_acc0, batch_acc1, batch_acc2, batch_acc3 = [], [], [], [], []    # 批次損失以及批次準確率\n",
    "    \n",
    "    # 測試集的 Loss 及 Accuracy\n",
    "    for iteration in range(NUM_ITERATION_TEST):\n",
    "        \n",
    "        # 批次處理\n",
    "        start = iteration * BATCH_SIZE\n",
    "        end = start + BATCH_SIZE\n",
    "        batch_X, batch_y = get_next_batch(X_test, y_test, start, end)\n",
    "        batch_y0, batch_y1, batch_y2, batch_y3 = split_batch_label(batch_y)\n",
    "        \n",
    "        # 取得該批次的 loss 及 Accuracy\n",
    "        feed_dict_test = {X: batch_X, y0: batch_y0, y1: batch_y1, y2: batch_y2, y3: batch_y3, drop: 1}\n",
    "        loss, acc0, acc1, acc2, acc3 = sess.run([totalLoss, accuracy0, accuracy1, accuracy2, accuracy3],\n",
    "                                                feed_dict={X: batch_X, y0: batch_y0, y1: batch_y1, y2: batch_y2, y3: batch_y3, \n",
    "                                                           drop: 1, lamb: 0})\n",
    "        batch_loss.append(loss)\n",
    "        batch_acc0.append(acc0)\n",
    "        batch_acc1.append(acc1)\n",
    "        batch_acc2.append(acc2)\n",
    "        batch_acc3.append(acc3)\n",
    "        \n",
    "    # 計算平均 loss 及 Accuracy\n",
    "    avg_loss = np.mean(batch_loss)\n",
    "    avg_acc0 = np.mean(batch_acc0)\n",
    "    avg_acc1 = np.mean(batch_acc1)\n",
    "    avg_acc2 = np.mean(batch_acc2)\n",
    "    avg_acc3 = np.mean(batch_acc3)\n",
    "\n",
    "    print('---------------------------------------------------------------------------')\n",
    "    print('test_loss: {:.3f}\\t Test Accuracy: {:.2f}, {:.2f}, {:.2f}, {:.2f}'.\n",
    "          format(avg_loss, avg_acc0, avg_acc1, avg_acc2, avg_acc3))\n",
    "    print('___________________________________________________________________________\\n\\n')\n",
    "\n",
    "# save_path = saver.save(sess, '../save_model/model.ckpt')\n",
    "tflite_model = tf.lite.toco_convert(sess.graph_def, [X, drop], [y_pred0, y_pred1, y_pred2, y_pred3])\n",
    "open('../tfliteModel/model.tflite', \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = randomize(X_train, y_train)\n",
    "batch_X, batch_y = get_next_batch(X_train, y_train, 0, 10)\n",
    "pred0, pred1, pred2, pred3 = sess.run([y_pred0, y_pred1, y_pred2, y_pred3], feed_dict={X: batch_X, drop: 1, lamb: 0})\n",
    "\n",
    "pred0 = np.argmax(pred0, axis=1)\n",
    "pred1 = np.argmax(pred1, axis=1)\n",
    "pred2 = np.argmax(pred2, axis=1)\n",
    "pred3 = np.argmax(pred3, axis=1)\n",
    "\n",
    "fig = plt.figure(figsize=(20, 5))\n",
    "for i in range(10):\n",
    "    # 顯示圖片\n",
    "    ax = plt.subplot(2, 5, i+1)\n",
    "    ax.imshow(batch_X[i], cmap='gray')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # 處理標籤\n",
    "    y = ''\n",
    "    for index in range(len(batch_y[i])):\n",
    "        y += chr(batch_y[i][index]+65)\n",
    "    title_real = y\n",
    "    title_predict = chr(pred0[i]+65) + chr(pred1[i]+65) + chr(pred2[i]+65) + chr(pred3[i]+65)\n",
    "    title = 'Real=' + title_real + '\\n' + 'predict=' + title_predict\n",
    "    \n",
    "    # 如果預測錯誤，將顯示不相等\n",
    "    if title_real != title_predict:\n",
    "        title += '\\n' + 'Not equal'\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = randomize(X_test, y_test)\n",
    "batch_X, batch_y = get_next_batch(X_test, y_test, 0, 10)\n",
    "pred0, pred1, pred2, pred3 = sess.run([y_pred0, y_pred1, y_pred2, y_pred3], feed_dict={X: batch_X, drop: 1, lamb: 0})\n",
    "\n",
    "pred0 = np.argmax(pred0, axis=1)\n",
    "pred1 = np.argmax(pred1, axis=1)\n",
    "pred2 = np.argmax(pred2, axis=1)\n",
    "pred3 = np.argmax(pred3, axis=1)\n",
    "\n",
    "fig = plt.figure(figsize=(20, 5))\n",
    "for i in range(10):\n",
    "    # 顯示圖片\n",
    "    ax = plt.subplot(2, 5, i+1)\n",
    "    ax.imshow(batch_X[i], cmap='gray')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # 處理標籤\n",
    "    y = ''\n",
    "    for index in range(len(batch_y[i])):\n",
    "        y += chr(batch_y[i][index]+65)\n",
    "    title_real = y\n",
    "    title_predict = chr(pred0[i]+65) + chr(pred1[i]+65) + chr(pred2[i]+65) + chr(pred3[i]+65)\n",
    "    title = 'Real=' + title_real + '\\n' + 'predict=' + title_predict\n",
    "    \n",
    "    # 如果預測錯誤，將顯示不相等\n",
    "    if title_real != title_predict:\n",
    "        title += '\\n' + 'Not equal'\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
