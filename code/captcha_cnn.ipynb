{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 圖片前處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['..\\\\data\\\\PDWB.jpg',\n",
       " '..\\\\data\\\\IDTZ.jpg',\n",
       " '..\\\\data\\\\YKTY.jpg',\n",
       " '..\\\\data\\\\LHDX.jpg',\n",
       " '..\\\\data\\\\VUIY.jpg']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_filenames(dataset_dir):\n",
    "    captcha_names = []\n",
    "    for filename in sorted(os.listdir(dataset_dir)):\n",
    "        path = os.path.join(dataset_dir, filename)\n",
    "        captcha_names.append(path)\n",
    "    return captcha_names\n",
    "\n",
    "dataPath = r'..\\data'\n",
    "\n",
    "image_filenames = get_filenames(dataPath)    # 取得所有圖片的檔案路徑\n",
    "random.shuffle(image_filenames)              # 打亂順序\n",
    "\n",
    "n_train = 5600    # 訓練集數量\n",
    "train_filenames = image_filenames[:n_train]    # 訓練集片的檔案路徑\n",
    "test_filenames = image_filenames[n_train:]     # 測試集片的檔案路徑\n",
    "\n",
    "# SHOW\n",
    "train_filenames[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Converting image and label 5600/5600\n",
      ">> Converting image and label 1400/1400\n",
      "X_train: (5600, 40, 120)\n",
      "y_train: (5600, 4)\n",
      "X_test: (1400, 40, 120)\n",
      "y_test: (1400, 4)\n",
      "[15  3 22  1]\n"
     ]
    }
   ],
   "source": [
    "def convert_dataset(filenames):\n",
    "    \n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for i, filename in enumerate(filenames):\n",
    "        oneHots = []\n",
    "        sys.stdout.write('\\r>> Converting image and label %d/%d' % (i + 1, len(filenames)))\n",
    "        sys.stdout.flush()\n",
    "        time.sleep(0.0001)\n",
    "        \n",
    "        # 處理圖片\n",
    "        img = cv2.imread(filename)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        img = np.asarray(img)\n",
    "        img[img>=img[0, :]-5]=255\n",
    "        img[img>=img[-1, :]-5]=255\n",
    "        \n",
    "        img = img * 1.7\n",
    "        img[img>255] = 255.0\n",
    "        img[img<255] = 0\n",
    "        \n",
    "        img = img.astype('uint8')\n",
    "        img = cv2.fastNlMeansDenoising(img, None, 65, 7, 21)\n",
    "        img[img>230]=255\n",
    "        img[img<255]=0\n",
    "        \n",
    "        img = img.astype(float)\n",
    "        img = img / 255.0              # 0 to 1\n",
    "        img = np.subtract(img, 0.5)    # -0.5 to 0.5\n",
    "        img = np.multiply(img, 2.0)    # -1 to 1\n",
    "        \n",
    "\n",
    "        \n",
    "        # 處理標籤\n",
    "        label = filename.split('\\\\')[-1][:4]    # 取得驗證碼(檔名)\n",
    "        \n",
    "        for i in range(len(label)):\n",
    "            oneHots.append(ord(label[i])-65)\n",
    "        \n",
    "        # append feature\n",
    "        images.append(img)\n",
    "        labels.append(oneHots)\n",
    "    \n",
    "    sys.stdout.write('\\n')\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "X_train, y_train = convert_dataset(train_filenames)\n",
    "X_test, y_test = convert_dataset(test_filenames)\n",
    "\n",
    "# SHOW\n",
    "print('X_train:', X_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('X_test:', X_test.shape)\n",
    "print('y_test:', y_test.shape)\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 檢測數據"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "idx = random.randint(0, 4000)\n",
    "y = ''\n",
    "for index in range(len(y_train[idx])):\n",
    "    y += chr(y_train[idx][index]+65)\n",
    "plt.imshow(X_train[idx], cmap='gray')\n",
    "plt.title(y, fontsize=18)\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建構網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 10    #80\n",
    "BATCH_SIZE = 20\n",
    "DROPOUT = 0.7\n",
    "LAMBDA = 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(input_, W, b, name):\n",
    "    with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n",
    "        x = tf.nn.conv2d(input_, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "def flatten(layer):\n",
    "    num_features = layer.shape[1:].num_elements()\n",
    "    flat = tf.reshape(layer, [-1, num_features])\n",
    "    return flat\n",
    "\n",
    "def get_weight_bias(weight_size, layer):\n",
    "    weight = tf.Variable(tf.random_normal(weight_size), name='w'+layer)\n",
    "    bias = tf.Variable(tf.random_normal([weight_size[-1]]), name='b'+layer)\n",
    "    return weight, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def captcha_network(inputs, num_classes):\n",
    "    W1, b1 = get_weight_bias([3, 3, 1, 64], '1')\n",
    "    W2, b2 = get_weight_bias([3, 3, 64, 128], '2')\n",
    "\n",
    "    l2_regularization = tf.nn.l2_loss(W1) + tf.nn.l2_loss(W2)\n",
    "        \n",
    "    x = conv2d(inputs, W1, b1, name='conv1')\n",
    "    x = tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME', name='pool1')\n",
    "        \n",
    "    x = conv2d(x, W2, b2, name='conv2')\n",
    "    x = tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME', name='pool2')\n",
    "        \n",
    "    x = tf.nn.dropout(x, drop)\n",
    "        \n",
    "    x = flatten(x)\n",
    "        \n",
    "    x0 = tf.layers.dense(x, units=26, name='x0')\n",
    "    x1 = tf.layers.dense(x, units=26, name='x1')\n",
    "    x2 = tf.layers.dense(x, units=26, name='x2')\n",
    "    x3 = tf.layers.dense(x, units=26, name='x3')\n",
    "    \n",
    "    return l2_regularization, x0, x1, x2, x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 40, 120], name='input')\n",
    "y0 = tf.placeholder(tf.float32, [None])\n",
    "y1 = tf.placeholder(tf.float32, [None])\n",
    "y2 = tf.placeholder(tf.float32, [None])\n",
    "y3 = tf.placeholder(tf.float32, [None])\n",
    "drop = tf.placeholder(tf.float32, name='dropout')\n",
    "lamb = tf.placeholder(tf.float32, name='lambda')\n",
    "\n",
    "X_reshape = tf.expand_dims(X, -1)    # 將尺寸1插入張量的維度\n",
    "regularization, logit0, logit1, logit2, logit3 = captcha_network(X_reshape, 26)\n",
    "\n",
    "oneHotLabel0 = tf.one_hot(indices=tf.cast(y0, tf.int32), depth=26)\n",
    "oneHotLabel1 = tf.one_hot(indices=tf.cast(y1, tf.int32), depth=26)\n",
    "oneHotLabel2 = tf.one_hot(indices=tf.cast(y2, tf.int32), depth=26)\n",
    "oneHotLabel3 = tf.one_hot(indices=tf.cast(y3, tf.int32), depth=26)\n",
    "\n",
    "\n",
    "# loss\n",
    "loss0 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=oneHotLabel0, logits=logit0))\n",
    "loss1 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=oneHotLabel1, logits=logit1))\n",
    "loss2 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=oneHotLabel2, logits=logit2))\n",
    "loss3 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=oneHotLabel3, logits=logit3))\n",
    "\n",
    "totalLoss = (loss0+loss1+loss2+loss3)/4 + lamb*regularization\n",
    "\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE).minimize(totalLoss)\n",
    "\n",
    "\n",
    "# accuracy\n",
    "y_pred0 = tf.nn.softmax(logit0, name='pred0')\n",
    "y_pred1 = tf.nn.softmax(logit1, name='pred1')\n",
    "y_pred2 = tf.nn.softmax(logit2, name='pred2')\n",
    "y_pred3 = tf.nn.softmax(logit3, name='pred3')\n",
    "\n",
    "correct_pre0 = tf.equal(tf.argmax(oneHotLabel0, 1), tf.argmax(y_pred0, 1))\n",
    "correct_pre1 = tf.equal(tf.argmax(oneHotLabel1, 1), tf.argmax(y_pred1, 1))\n",
    "correct_pre2 = tf.equal(tf.argmax(oneHotLabel2, 1), tf.argmax(y_pred2, 1))\n",
    "correct_pre3 = tf.equal(tf.argmax(oneHotLabel3, 1), tf.argmax(y_pred3, 1))\n",
    "    \n",
    "accuracy0 = tf.reduce_mean(tf.cast(correct_pre0, tf.float32))\n",
    "accuracy1 = tf.reduce_mean(tf.cast(correct_pre1, tf.float32))\n",
    "accuracy2 = tf.reduce_mean(tf.cast(correct_pre2, tf.float32))\n",
    "accuracy3 = tf.reduce_mean(tf.cast(correct_pre3, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomize(x, y):\n",
    "    permutation = np.random.permutation(y.shape[0])\n",
    "    shuffled_x = x[permutation, :]\n",
    "    shuffled_y = y[permutation]\n",
    "    return shuffled_x, shuffled_y\n",
    "\n",
    "def get_next_batch(x, y, start, end):\n",
    "    x_batch = x[start:end]\n",
    "    y_batch = y[start:end]\n",
    "    return x_batch, y_batch\n",
    "\n",
    "def split_batch_label(batchLabel):\n",
    "    batchLabel0 = [splitLabel[0] for splitLabel in batchLabel]\n",
    "    batchLabel1 = [splitLabel[1] for splitLabel in batchLabel]\n",
    "    batchLabel2 = [splitLabel[2] for splitLabel in batchLabel]\n",
    "    batchLabel3 = [splitLabel[3] for splitLabel in batchLabel]\n",
    "    return batchLabel0, batchLabel1, batchLabel2, batchLabel3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________________________________________________________________\n",
      "Epoch: 1\n",
      "---------------------------------------------------------------------------\n",
      "Iteration: 20/280\t loss: 2355.181\t Accuracy: 0.00, 0.00, 0.05, 0.05\n",
      "Iteration: 40/280\t loss: 487.987\t Accuracy: 0.05, 0.20, 0.10, 0.10\n",
      "Iteration: 60/280\t loss: 156.298\t Accuracy: 0.30, 0.05, 0.20, 0.20\n",
      "Iteration: 80/280\t loss: 70.289\t Accuracy: 0.25, 0.15, 0.30, 0.15\n",
      "Iteration: 100/280\t loss: 57.324\t Accuracy: 0.40, 0.35, 0.55, 0.25\n",
      "Iteration: 120/280\t loss: 24.622\t Accuracy: 0.60, 0.60, 0.60, 0.25\n",
      "Iteration: 140/280\t loss: 26.226\t Accuracy: 0.65, 0.50, 0.55, 0.55\n",
      "Iteration: 160/280\t loss: 17.728\t Accuracy: 0.60, 0.60, 0.30, 0.70\n",
      "Iteration: 180/280\t loss: 19.754\t Accuracy: 0.70, 0.70, 0.65, 0.55\n",
      "Iteration: 200/280\t loss: 8.894\t Accuracy: 0.80, 0.80, 0.80, 0.65\n",
      "Iteration: 220/280\t loss: 15.720\t Accuracy: 0.60, 0.55, 0.65, 0.70\n",
      "Iteration: 240/280\t loss: 8.660\t Accuracy: 0.75, 0.75, 0.85, 0.80\n",
      "Iteration: 260/280\t loss: 6.762\t Accuracy: 0.80, 0.85, 0.80, 0.70\n",
      "Iteration: 280/280\t loss: 6.515\t Accuracy: 0.85, 0.90, 0.70, 0.85\n",
      "---------------------------------------------------------------------------\n",
      "test_loss: 11.857\t Test Accuracy: 0.79, 0.73, 0.74, 0.71\n",
      "___________________________________________________________________________\n",
      "\n",
      "\n",
      "___________________________________________________________________________\n",
      "Epoch: 2\n",
      "---------------------------------------------------------------------------\n",
      "Iteration: 20/280\t loss: 4.769\t Accuracy: 0.80, 0.80, 0.85, 0.95\n",
      "Iteration: 40/280\t loss: 3.848\t Accuracy: 0.90, 0.95, 0.85, 0.80\n",
      "Iteration: 60/280\t loss: 2.162\t Accuracy: 1.00, 0.80, 1.00, 0.90\n",
      "Iteration: 80/280\t loss: 7.269\t Accuracy: 0.75, 0.95, 0.85, 0.85\n",
      "Iteration: 100/280\t loss: 1.298\t Accuracy: 1.00, 1.00, 0.85, 0.90\n",
      "Iteration: 120/280\t loss: 3.705\t Accuracy: 0.95, 0.85, 0.85, 0.90\n",
      "Iteration: 140/280\t loss: 2.846\t Accuracy: 0.95, 0.75, 0.90, 0.85\n",
      "Iteration: 160/280\t loss: 2.985\t Accuracy: 0.85, 0.85, 0.90, 1.00\n",
      "Iteration: 180/280\t loss: 2.482\t Accuracy: 0.80, 1.00, 1.00, 0.85\n",
      "Iteration: 200/280\t loss: 2.163\t Accuracy: 0.90, 1.00, 0.85, 0.90\n",
      "Iteration: 220/280\t loss: 3.542\t Accuracy: 0.85, 0.95, 1.00, 0.70\n",
      "Iteration: 240/280\t loss: 2.850\t Accuracy: 0.90, 0.80, 0.75, 0.90\n",
      "Iteration: 260/280\t loss: 1.300\t Accuracy: 0.85, 0.95, 0.90, 0.90\n",
      "Iteration: 280/280\t loss: 4.095\t Accuracy: 0.90, 0.90, 0.90, 0.85\n",
      "---------------------------------------------------------------------------\n",
      "test_loss: 5.443\t Test Accuracy: 0.85, 0.90, 0.86, 0.84\n",
      "___________________________________________________________________________\n",
      "\n",
      "\n",
      "___________________________________________________________________________\n",
      "Epoch: 3\n",
      "---------------------------------------------------------------------------\n",
      "Iteration: 20/280\t loss: 1.599\t Accuracy: 0.90, 0.95, 0.95, 0.90\n",
      "Iteration: 40/280\t loss: 1.146\t Accuracy: 0.95, 0.90, 1.00, 0.95\n",
      "Iteration: 60/280\t loss: 2.128\t Accuracy: 0.95, 0.95, 1.00, 1.00\n",
      "Iteration: 80/280\t loss: 0.796\t Accuracy: 1.00, 0.95, 0.95, 0.95\n",
      "Iteration: 100/280\t loss: 1.108\t Accuracy: 1.00, 0.95, 0.95, 0.85\n",
      "Iteration: 120/280\t loss: 3.213\t Accuracy: 0.85, 1.00, 0.95, 0.85\n",
      "Iteration: 140/280\t loss: 2.455\t Accuracy: 1.00, 0.75, 0.95, 1.00\n",
      "Iteration: 160/280\t loss: 0.006\t Accuracy: 1.00, 1.00, 1.00, 1.00\n",
      "Iteration: 180/280\t loss: 0.585\t Accuracy: 0.90, 0.95, 0.95, 1.00\n",
      "Iteration: 200/280\t loss: 1.250\t Accuracy: 0.95, 0.90, 1.00, 1.00\n",
      "Iteration: 220/280\t loss: 0.610\t Accuracy: 1.00, 0.95, 1.00, 1.00\n",
      "Iteration: 240/280\t loss: 2.105\t Accuracy: 0.95, 0.95, 0.95, 0.90\n",
      "Iteration: 260/280\t loss: 0.391\t Accuracy: 1.00, 1.00, 0.95, 1.00\n",
      "Iteration: 280/280\t loss: 0.636\t Accuracy: 1.00, 0.95, 0.95, 0.95\n",
      "---------------------------------------------------------------------------\n",
      "test_loss: 3.335\t Test Accuracy: 0.92, 0.85, 0.93, 0.90\n",
      "___________________________________________________________________________\n",
      "\n",
      "\n",
      "___________________________________________________________________________\n",
      "Epoch: 4\n",
      "---------------------------------------------------------------------------\n",
      "Iteration: 20/280\t loss: 0.217\t Accuracy: 0.95, 1.00, 1.00, 0.95\n",
      "Iteration: 40/280\t loss: 0.906\t Accuracy: 1.00, 0.95, 0.95, 1.00\n",
      "Iteration: 60/280\t loss: 0.000\t Accuracy: 1.00, 1.00, 1.00, 1.00\n",
      "Iteration: 80/280\t loss: 0.814\t Accuracy: 1.00, 1.00, 0.85, 0.95\n",
      "Iteration: 100/280\t loss: 0.613\t Accuracy: 1.00, 0.95, 0.95, 1.00\n",
      "Iteration: 120/280\t loss: 0.668\t Accuracy: 1.00, 0.90, 1.00, 1.00\n",
      "Iteration: 140/280\t loss: 0.362\t Accuracy: 0.95, 1.00, 1.00, 0.95\n",
      "Iteration: 160/280\t loss: 0.440\t Accuracy: 0.95, 0.95, 1.00, 1.00\n",
      "Iteration: 180/280\t loss: 0.838\t Accuracy: 0.90, 1.00, 0.95, 0.90\n",
      "Iteration: 200/280\t loss: 0.194\t Accuracy: 0.95, 1.00, 1.00, 1.00\n",
      "Iteration: 220/280\t loss: 0.936\t Accuracy: 1.00, 1.00, 0.95, 0.95\n",
      "Iteration: 240/280\t loss: 0.065\t Accuracy: 1.00, 1.00, 1.00, 0.95\n",
      "Iteration: 260/280\t loss: 0.000\t Accuracy: 1.00, 1.00, 1.00, 1.00\n",
      "Iteration: 280/280\t loss: 0.683\t Accuracy: 1.00, 1.00, 0.95, 0.95\n",
      "---------------------------------------------------------------------------\n",
      "test_loss: 3.505\t Test Accuracy: 0.92, 0.91, 0.91, 0.86\n",
      "___________________________________________________________________________\n",
      "\n",
      "\n",
      "___________________________________________________________________________\n",
      "Epoch: 5\n",
      "---------------------------------------------------------------------------\n",
      "Iteration: 20/280\t loss: 0.000\t Accuracy: 1.00, 1.00, 1.00, 1.00\n",
      "Iteration: 40/280\t loss: 0.115\t Accuracy: 1.00, 0.95, 1.00, 1.00\n",
      "Iteration: 60/280\t loss: 0.275\t Accuracy: 1.00, 1.00, 0.95, 0.95\n",
      "Iteration: 80/280\t loss: 0.265\t Accuracy: 1.00, 1.00, 0.95, 1.00\n",
      "Iteration: 100/280\t loss: 0.107\t Accuracy: 0.95, 1.00, 1.00, 1.00\n",
      "Iteration: 120/280\t loss: 0.222\t Accuracy: 1.00, 1.00, 0.95, 1.00\n",
      "Iteration: 140/280\t loss: 0.306\t Accuracy: 1.00, 0.95, 1.00, 0.95\n",
      "Iteration: 160/280\t loss: 0.006\t Accuracy: 1.00, 1.00, 1.00, 1.00\n",
      "Iteration: 180/280\t loss: 0.299\t Accuracy: 1.00, 0.95, 1.00, 1.00\n",
      "Iteration: 200/280\t loss: 0.629\t Accuracy: 1.00, 0.95, 0.95, 0.95\n",
      "Iteration: 220/280\t loss: 0.226\t Accuracy: 1.00, 1.00, 0.95, 1.00\n",
      "Iteration: 240/280\t loss: 0.821\t Accuracy: 1.00, 0.95, 1.00, 1.00\n",
      "Iteration: 260/280\t loss: 0.570\t Accuracy: 1.00, 0.95, 1.00, 1.00\n",
      "Iteration: 280/280\t loss: 0.001\t Accuracy: 1.00, 1.00, 1.00, 1.00\n",
      "---------------------------------------------------------------------------\n",
      "test_loss: 2.039\t Test Accuracy: 0.94, 0.93, 0.93, 0.92\n",
      "___________________________________________________________________________\n",
      "\n",
      "\n",
      "___________________________________________________________________________\n",
      "Epoch: 6\n",
      "---------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-649aa6cfd596>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;31m# 執行權重優化\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         sess.run(train_op, \n\u001b[1;32m---> 26\u001b[1;33m                  feed_dict={X: batch_X, y0: batch_y0, y1: batch_y1, y2: batch_y2, y3: batch_y3, drop: DROPOUT, lamb: LAMBDA})\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;31m# 印出訓練集的 Loss 以及 Accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "NUM_ITERATION = int(len(y_train) / BATCH_SIZE)         # 跑完一個 epoch 所需要的 iteration 次數\n",
    "NUM_ITERATION_TEST = int(len(y_test) / BATCH_SIZE)     # 跑完一個 test set 所需要的 iteration 次數\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('___________________________________________________________________________')\n",
    "    print('Epoch: {}'.format(epoch + 1))\n",
    "    print('---------------------------------------------------------------------------')\n",
    "    \n",
    "    X_train, y_train = randomize(X_train, y_train)    # 打亂訓練集，避免每次批次都是相同的圖片分布\n",
    "\n",
    "    for iteration in range(NUM_ITERATION):\n",
    "        \n",
    "        # 批次處理\n",
    "        start = iteration * BATCH_SIZE\n",
    "        end = start + BATCH_SIZE\n",
    "        batch_X, batch_y = get_next_batch(X_train, y_train, start, end)\n",
    "        batch_y0, batch_y1, batch_y2, batch_y3 = split_batch_label(batch_y)\n",
    "        \n",
    "        # 執行權重優化\n",
    "        sess.run(train_op, \n",
    "                 feed_dict={X: batch_X, y0: batch_y0, y1: batch_y1, y2: batch_y2, y3: batch_y3, drop: DROPOUT, lamb: LAMBDA})\n",
    "        \n",
    "        # 印出訓練集的 Loss 以及 Accuracy\n",
    "        if (iteration+1) % 20 == 0:\n",
    "            \n",
    "            # 取得該批次的 loss 及 Accuracy\n",
    "            loss, acc0, acc1, acc2, acc3 = sess.run([totalLoss, accuracy0, accuracy1, accuracy2, accuracy3], \n",
    "                                                    feed_dict={X: batch_X, y0: batch_y0, y1: batch_y1, y2: batch_y2, y3: batch_y3, \n",
    "                                                               drop: DROPOUT, lamb: 0})\n",
    "            \n",
    "            print('Iteration: {:2d}/{}\\t loss: {:.3f}\\t Accuracy: {:.2f}, {:.2f}, {:.2f}, {:.2f}'\n",
    "                  .format(iteration+1, NUM_ITERATION, loss, acc0, acc1, acc2, acc3))\n",
    "\n",
    "\n",
    "    batch_loss, batch_acc0, batch_acc1, batch_acc2, batch_acc3 = [], [], [], [], []    # 批次損失以及批次準確率\n",
    "    \n",
    "    # 測試集的 Loss 及 Accuracy\n",
    "    for iteration in range(NUM_ITERATION_TEST):\n",
    "        \n",
    "        # 批次處理\n",
    "        start = iteration * BATCH_SIZE\n",
    "        end = start + BATCH_SIZE\n",
    "        batch_X, batch_y = get_next_batch(X_test, y_test, start, end)\n",
    "        batch_y0, batch_y1, batch_y2, batch_y3 = split_batch_label(batch_y)\n",
    "        \n",
    "        # 取得該批次的 loss 及 Accuracy\n",
    "        feed_dict_test = {X: batch_X, y0: batch_y0, y1: batch_y1, y2: batch_y2, y3: batch_y3, drop: 1}\n",
    "        loss, acc0, acc1, acc2, acc3 = sess.run([totalLoss, accuracy0, accuracy1, accuracy2, accuracy3],\n",
    "                                                feed_dict={X: batch_X, y0: batch_y0, y1: batch_y1, y2: batch_y2, y3: batch_y3, \n",
    "                                                           drop: 1, lamb: 0})\n",
    "        batch_loss.append(loss)\n",
    "        batch_acc0.append(acc0)\n",
    "        batch_acc1.append(acc1)\n",
    "        batch_acc2.append(acc2)\n",
    "        batch_acc3.append(acc3)\n",
    "        \n",
    "    # 計算平均 loss 及 Accuracy\n",
    "    avg_loss = np.mean(batch_loss)\n",
    "    avg_acc0 = np.mean(batch_acc0)\n",
    "    avg_acc1 = np.mean(batch_acc1)\n",
    "    avg_acc2 = np.mean(batch_acc2)\n",
    "    avg_acc3 = np.mean(batch_acc3)\n",
    "\n",
    "    print('---------------------------------------------------------------------------')\n",
    "    print('test_loss: {:.3f}\\t Test Accuracy: {:.2f}, {:.2f}, {:.2f}, {:.2f}'.\n",
    "          format(avg_loss, avg_acc0, avg_acc1, avg_acc2, avg_acc3))\n",
    "    print('___________________________________________________________________________\\n\\n')\n",
    "\n",
    "# save_path = saver.save(sess, '../save_model/model.ckpt')\n",
    "# tflite_model = tf.lite.toco_convert(sess.graph_def, [X, drop], [y_pred0, y_pred1, y_pred2, y_pred3])\n",
    "# open('../tfliteModel/model.tflite', \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = randomize(X_train, y_train)\n",
    "batch_X, batch_y = get_next_batch(X_train, y_train, 0, 10)\n",
    "pred0, pred1, pred2, pred3 = sess.run([y_pred0, y_pred1, y_pred2, y_pred3], feed_dict={X: batch_X, drop: 1, lamb: 0})\n",
    "\n",
    "pred0 = np.argmax(pred0, axis=1)\n",
    "pred1 = np.argmax(pred1, axis=1)\n",
    "pred2 = np.argmax(pred2, axis=1)\n",
    "pred3 = np.argmax(pred3, axis=1)\n",
    "\n",
    "fig = plt.figure(figsize=(20, 5))\n",
    "for i in range(10):\n",
    "    # 顯示圖片\n",
    "    ax = plt.subplot(2, 5, i+1)\n",
    "    ax.imshow(batch_X[i], cmap='gray')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # 處理標籤\n",
    "    y = ''\n",
    "    for index in range(len(batch_y[i])):\n",
    "        y += chr(batch_y[i][index]+65)\n",
    "    title_real = y\n",
    "    title_predict = chr(pred0[i]+65) + chr(pred1[i]+65) + chr(pred2[i]+65) + chr(pred3[i]+65)\n",
    "    title = 'Real=' + title_real + '\\n' + 'predict=' + title_predict\n",
    "    \n",
    "    # 如果預測錯誤，將顯示不相等\n",
    "    if title_real != title_predict:\n",
    "        title += '\\n' + 'Not equal'\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = randomize(X_test, y_test)\n",
    "batch_X, batch_y = get_next_batch(X_test, y_test, 0, 10)\n",
    "pred0, pred1, pred2, pred3 = sess.run([y_pred0, y_pred1, y_pred2, y_pred3], feed_dict={X: batch_X, drop: 1, lamb: 0})\n",
    "\n",
    "pred0 = np.argmax(pred0, axis=1)\n",
    "pred1 = np.argmax(pred1, axis=1)\n",
    "pred2 = np.argmax(pred2, axis=1)\n",
    "pred3 = np.argmax(pred3, axis=1)\n",
    "\n",
    "fig = plt.figure(figsize=(20, 5))\n",
    "for i in range(10):\n",
    "    # 顯示圖片\n",
    "    ax = plt.subplot(2, 5, i+1)\n",
    "    ax.imshow(batch_X[i], cmap='gray')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # 處理標籤\n",
    "    y = ''\n",
    "    for index in range(len(batch_y[i])):\n",
    "        y += chr(batch_y[i][index]+65)\n",
    "    title_real = y\n",
    "    title_predict = chr(pred0[i]+65) + chr(pred1[i]+65) + chr(pred2[i]+65) + chr(pred3[i]+65)\n",
    "    title = 'Real=' + title_real + '\\n' + 'predict=' + title_predict\n",
    "    \n",
    "    # 如果預測錯誤，將顯示不相等\n",
    "    if title_real != title_predict:\n",
    "        title += '\\n' + 'Not equal'\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
